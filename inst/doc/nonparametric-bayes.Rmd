Non-parametric approaches to optimal policy are more robust
===========================================================

Carl Boettiger, Steve Munch, Marc Mangel

# Abstract


# Introduction

Problem of structural uncertainty in managing ecological systems.  Motivate via the widespread concern of tipping points, more general concerns of complex/nonlinear dynamics.  


Typical approaches using parametric models.  motivation/strengths (mechanistic underpinnings, computationally simple/potentially analytic solutions.  Parametric structure makes it difficult to represent uncertainty accurately in areas where data is not available.  


### Discussion of previous decision theory literature on the vulnerability of parametric methods

* Parametric vs structural uncertainty
* Alternative approaches: POMDP, etc.  


# Approach and Methods


```{r image-options, echo = FALSE, cache = FALSE, external = TRUE, include = FALSE}
opts_chunk$set(cache = TRUE, cache.path = "writeup/", warning = FALSE, message = FALSE,
               comment = NA, tidy = FALSE, echo = FALSE)
opts_knit$set(upload.fun = socialR::notebook.url)
#opts_chunk$set(dev = 'Cairo_pdf', dev.args=list(""))
opts_chunk$set(dev="png", dev.args=list(bg="transparent"))
```
```{r libraries, include=FALSE}
library(pdgControl)
library(nonparametricbayes)
library(reshape2)
library(ggplot2)
library(data.table)
library(tgp)
library(MCMCpack)
library(plyr)
library(knitcitations)
```
```{r plotting-options, echo=FALSE, include=FALSE}
theme_set(theme_bw(base_size=16))
theme_update(panel.background = element_rect(fill = "transparent",colour = NA),
             plot.background = element_rect(fill = "transparent",colour = NA))
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
#sha <- gsub("^commit ", "", system("git log -n 1", intern=TRUE)[1])
#short_sha <- gsub("(^.{10}).*", "\\1", sha)
#date <- format(Sys.time(), "%Y-%m-%d__%H-%M-%S")
#opts_chunk$set(fig.path = paste("figure/", date, "-", short_sha, "-", sep=""))
```

### Discussion of state equation
```{r stateeq}
f <- RickerAllee
# c(5, 10, 5) is 2-cycle, c(5.5, 10, 5) is 6 cycle, 5.3 is about 4
p <- c(2, 10, 5) 
K <- 10
allee <- 5
```


To illustrate (the pitfalls of decision theory based on parametric assumptions and compare the performance of a non-parametric approach) these challenges, we use a simple parametric model for a single species [derived from fist principles by @Allen].  This model contains an Allee effect, or level below which the population is not self-sustaining and shrinks to zero [@Courchamp].  Model containing such "Tipping point" phenomena have become of particular interest ...

$$\begin{align}
X_{t+1} &= Z_t f(S_t) \\
S_t &= X_t - h_t \\
f(S_t) &= e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)}
\end{align}$$


```{r sdp-pars, dependson="stateeq"}
sigma_g <- 0.05
sigma_m <- 0.0
z_g <- function() rlnorm(1, 0, sigma_g)
z_m <- function() 1+(2*runif(1, 0,  1)-1) * sigma_m
x_grid <- seq(0, 1.5 * K, length=101)
h_grid <- x_grid
profit <- function(x,h) pmin(x, h)
delta <- 0.01
OptTime <- 20  # stationarity with unstable models is tricky thing
reward <- 0
xT <- 0
seed_i <- 1
Xo <- K # observations start from
x0 <- Xo # simulation under policy starts from
Tobs <- 35
```

Where $Z_t$ is multiplicative noise function with mean 1, representing stochastic growth. We will consider log-normal noise with shape parameter $\sigma_g$.  We start with an example in which the parameters are $r =$ `r p[1]`, $K =$ `r p[2]`, $C =$ `r p[3]`, and  $\sigma_g =$ `r sigma_g`.


### Discussion of training data

Both parametric and nonparametric approaches will require some training data on which to base their model of the process.  We generate the training data under the model described in Eq 1 for `r Tobs` timesteps, under a known but not necessarily optimal sequence of harvest intensities, $h_t$.  For simplicity we imagine a fishery that started from zero harvest pressure and has been gradually increasing the harvest.  (Motivation, alternatives, stationarity, examples without a stable node (limit-cycle models), examples based on observations near a stable node alone, and why that isn't impossible).  


```{r obs, dependson="sdp-pars"}
  obs <- sim_obs(Xo, z_g, f, p, Tobs=Tobs, nz=15, 
                 harvest = sort(rep(seq(0, .5, length=7), 5)), seed = seed_i)
```



### Discussion of maximum likelihood estimated models
```{r mle, dependson="obs"}
alt <- par_est(obs,  init = c(r = p[1], 
                              K = mean(obs$x[obs$x>0]), 
                              s = sigma_g))
est <- par_est_allee(obs, f, p,  
                     init = c(r = p[1] + rnorm(1), 
                              K = p[2] + rnorm(1), 
                              C = p[3] + rnorm(1), 
                              s = sigma_g))
```

We estimate two parametric models from the data using a maximum likelihood approach.  The first model is structurally identical to the true model (Eq 1), differing only in that it's parameters are estimated from the observed data rather than given.  The alternative model is the Ricker model, which is structurally similar and commonly assumed 


(MLE models will assume the noise is log-normal, which it is in the simulation).  


Which estimates a Ricker model with $r =$ `r alt$p[1]`, $K =$ `r alt$p[2]`, and the Allen Allele model with $r =$ `r est$p[1]`, $K =$ `r est$p[2]` and $C =$ `r est$p[3]`.  


### (Brief) Discussion of GP inference

The inference of the Gaussian process Following @Munch2005 

```{r gp-priors}
#inv gamma has mean b / (a - 1) (assuming a>1) and variance b ^ 2 / ((a - 2) * (a - 1) ^ 2) (assuming a>2)
s2.p <- c(5,5)  
tau2.p <- c(5,1)
d.p = c(10, 1/0.1, 10, 1/0.1)
nug.p = c(10, 1/0.1, 10, 1/0.1) # gamma mean
s2_prior <- function(x) dinvgamma(x, s2.p[1], s2.p[2])
tau2_prior <- function(x) dinvgamma(x, tau2.p[1], tau2.p[2])
d_prior <- function(x) dgamma(x, d.p[1], scale = d.p[2]) + dgamma(x, d.p[3], scale = d.p[4])
nug_prior <- function(x) dgamma(x, nug.p[1], scale = nug.p[2]) + dgamma(x, nug.p[3], scale = nug.p[4])
beta0_prior <- function(x, tau) dnorm(x, 0, tau)
beta = c(0)
priors <- list(s2 = s2_prior, tau2 = tau2_prior, beta0 = dnorm, nug = nug_prior, d = d_prior, ldetK = function(x) 0)
```

```{r gp, dependson=c("obs", "gp-priors")}
  gp <- bgp(X=obs$x, XX=x_grid, Z=obs$y, verb=0,
          meanfn="constant", bprior="b0", BTE=c(2000,16000,2),
          m0r1=FALSE, corr="exp", trace=TRUE, 
          beta = beta, s2.p = s2.p, d.p = d.p, nug.p = nug.p, tau2.p = tau2.p,
          s2.lam = "fixed", d.lam = "fixed", nug.lam = "fixed", tau2.lam = "fixed")      
```


###  Discussion of the dynamic programming solution

(More thorough, but general-audience targeted.  Technical details and code provided in appendices).

```{r opt, dependson=c("gp", "mle")}
  OPT <- optimal_policy(gp, f, est$f, alt$f,
                        p, est$p, alt$p,
                        x_grid, h_grid, sigma_g, 
                        sigma_g, sigma_g, # est$sigma_g, alt$sigma_g, but those ests are poor
                        delta, xT, profit, reward, OptTime)
```


### Discussion on how we compare performance of policies

```{r sim, dependson="opt"}
dt <- simulate_opt(OPT, f, p, x_grid, h_grid, x0, z_g, profit)
```

* Replicate stochastic simulations 
* Sensitivity analysis

# Results

## Figure 1: 

Inferred Gaussian Process compared to the true and parametric models.  

```{r gp_plot, dependson=c("gp", "mle"), fig.cap="Graph of the inferred Gaussian process compared to the true process and maximum-likelihood estimated process.  Graph shows the expected value for the function $f$ under each model.  Two standard deviations from the estimated Gaussian process covariance with (light grey) and without (darker grey) measurement error are also shown.  The training data is also shown as black points.  (The GP is conditioned on 0,0, shown as a pseudo-data point). "}
gp_plot(gp, f, p, est$f, est$p, alt$f, alt$p, x_grid, obs, seed_i)
```


## Figure 2: 

```{r policies_plot, dependson="opt", fig.cap="The steady-state optimal policy (infinite boundary) calculated under each model.  Policies are shown in terms of target escapement, $S_t$, as under models such as this a constant escapement policy is expected to be optimal [@Reed1979]."}
  plot_policies(x_grid, OPT$gp_D, OPT$est_D, OPT$true_D, OPT$alt_D)
```

## Figure 3: 

```{r sim_plot, dependson="sim", fig.cap="**Figure 3**: Gaussian process inference outperforms parametric estimates. Shown are 100 replicate simulations of the stock dynamics (eq 1) under the policies derived from each of the estimated models, as well as the policy based on the exact underlying model."}
ggplot(dt) + 
    geom_line(aes(time, fishstock, 
                  group=interaction(reps, method), 
                  color=method), alpha=.1) +
    scale_colour_manual(values=cbPalette, 
                        guide = guide_legend(override.aes = list(alpha = 1)))
```

## Figure 4:

Sensitivity analysis.  Distribution of yield over stochastic realizations. 



# Discussion / Conclusion


* Non-parametric methods have received far too little attention in ecological modeling efforts that are aimed at improved conservation planning and decision making support.  

* Importance of non-parametric approaches in conservation planning / resource management / decision theory.  

* Decision-theoretic tools such as optimal control calculations rely on robust _forecasting_ more strongly than they rely on accurate _mechanistic_ relationships.  

* Adapting a non-parametric approach requires modification of existing methods for decision theory.  We have illustrated how this might be done in the context of stochastic dynamic programming, opening the door for substantial further research into how these applications might be improved.  

* Anticipate improved relative performance in higher dimensional examples

* Constant escapement


## Future directions 

* Multiple species
* Online learning
* Multiple step-ahead predictions
* Additional uncertainties
* Improving inference of optimal policy from the GP

```{r echo=FALSE, results="asis"}
#bibliography("html")
```


# Appendix / Supplementary Materials

## MCMC posterior distributions and convergence analysis

```{r posteriors, dependson="gp", fig.cap = "Histogram of posterior distributions for the estimated Gaussian Process shown in Figure 1.  Prior distributions overlaid."}
  posteriors_plot(gp, priors) # needs trace=TRUE!
```
 
 @Gramacy2005
 
## Tables of nuisance parameters, sensitivity analysis

### List of hyperparameters, prior distributions and their parameters

## Reproducible code, "Research Compendium"



