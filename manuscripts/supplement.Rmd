---
layout: 12pt,review
linenumbers: true
title: "Supplement for: Avoiding tipping points in fisheries management through Gaussian Process Dynamic Programming"
author: 
  - name: Carl Boettiger
    affiliation: cstar
    email: cboettig(at)gmail.com
    footnote: Corresponding author
  - name: Marc Mangel
    affiliation: cstar
  - name: Stephan Munch
    affiliation: noaa
address: 
  - code: cstar
    address: | 
      Center for Stock Assessment Research, 
      Department of Applied Math and Statistics, 
      University of California, Mail Stop SOE-2,
      Santa Cruz, CA 95064, USA
  - code: marc
    address: |
      Center for Stock Assessment Research, Department of Applied Math
      and Statistics, University of California,
      Mail Stop SOE-2, Santa Cruz, CA 95064, USA and Department of
      Biology, University of Bergen, Bergen, Norway 9020
  - code: noaa
    address: | 
      Southwest Fisheries Science Center, 
      National Oceanic and Atmospheric Administration, 
      110 Shaffer Road, Santa Cruz, CA 95060, USA


bibliography: components/references.bib
csl: components/ecology.csl
documentclass: components/elsarticle

## rmarkdown render options
output:
  pdf_document:
    fig_caption: true
    template: components/elsarticle.latex
    keep_tex: true

---


```{r knit, include=FALSE}
library("methods")
library("rmarkdown")
render("manuscript.Rmd")
```

```{r supplement-caching, include=FALSE}
library("knitr")
basename <- "supplement"
opts_chunk$set(fig.path = paste("components/figure/", basename, "-", sep=""),
               cache.path = paste("components/cache/", basename, "/", sep=""))
opts_chunk$set(cache = 2) 
opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, 
               comment = NA, verbose = TRUE, echo=FALSE)

opts_chunk$set(dev.opts=c(version="1.3"), dev="pdf")

```




\appendix
\renewcommand*{\thefigure}{S\arabic{figure}}
\renewcommand*{\thetable}{S\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}


Figure S1 illustrates the performance of the GP and parametric models
outside the observed training data. The mean trajectory under the
underlying model is shown by the black dots, while the corresponding
prediction made by the model shown by the box and whiskers plots.
Predictions are based on the true expected value in the previous time
step.  Predicted distributions that lie entirely above the expected
dynamics indicate the expectation of stock sizes higher than what is
actually expected. The models differ both in their expectations and
their uncertainty (colored bands show two standard deviations away).
Note that the GP is particularly uncertain about the dynamics relative
to structurally incorrect models like the Ricker.


```{r figure_3, fig.width=8, fig.height=6, fig.cap="Outside the range of the training data (Figure 1), the true dynamics (black dots) fall outside the uncertainty (two standard deviations, colored bands) of the structurally incorrect parametric models (Ricker, Myers), but inside the uncertainty predicted by the GP. Points show the stock size simulated by the true model.  Overlay shows the range of states predicted by each model, based on the state observed in the previous time step. The Ricker model always (wrongly) predicts positive population growth, while the actual population shrinks in each step as the initial condition falls below the Allee threshold of the underlying model (Allen).  Note that because it does not assume a parametric form but instead relies more directly on the data, the GP is both more pessimistic and more uncertain about the future state than the parametric models.", dependson="plot-options"}
y <- numeric(8)
y[1] <- 4.5
for(t in 1:(length(y)-1))
      y[t+1] = z_g() * f(y[t], h=0, p=p)
# predicts means, does not reflect uncertainty estimate!
crash_data <- step_ahead_posteriors(y)
crash_data <- subset(crash_data, variable %in% c("GP", "Allen", "Ricker", "Myers"))
ggplot(crash_data) + 
  geom_boxplot(aes(as.factor(as.integer(time)), value, 
                   fill = variable, col=variable), 
               outlier.size=1, position="identity") + 
#  geom_line(aes(time, value, col = variable, 
#            group=interaction(L1,variable))) + 
  geom_point(aes(time, stock), size = 3) + 
  scale_fill_manual(values=colorkey[c("GP", "Allen", "Ricker", "Myers")]) +  
  scale_colour_manual(values=colorkey[c("GP", "Allen", "Ricker", "Myers")]) +  
  facet_wrap(~variable) + 
  theme(legend.position="none") + xlab("time") + ylab("stock size") 

write.csv(crash_data, "components/data/figure3.csv")
```





```{r figure_S1, fig.cap = "Traces from the MCMC estimates of the GP model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps)", dependson="plot-options"}
gp_assessment_plots$traces_plot
```


```{r figure_S2, fig.cap="Posterior distributions from the MCMC estimate of the GP model. Prior curves shown in red."}
gp_assessment_plots$posteriors_plot
```


\newpage



Training data (Figures 1-6)
----------------------------

Each of our models $f(S_t)$ must be estimated from training data, which
we simulate from the Allen model with parameters $r = $ `r p[1]`, 
$K =$ `r p[2]`, $C =$ `r p[3]`, and  $\sigma_g =$ `r sigma_g` 
for $T=$ `r Tobs` timesteps, starting at initial condition $X_0 = $ `r Xo`. 
The training data can be seen in Figure 1.  

Training data for sensitivity analyses
-------------------------------------

A further 96 unique training data sets are generated for the sensitivity analysis, as described in the main text.  



Code
----

All code used in producing this analysis can be found in the R package accompanying the paper, available from [http://github.com/cboettig/nonparametric-bayes]. The code for all results shown here is dynamically embedded into the manuscript using `knitr` [@knitr].  


<!--
Data
----

While the data can be regenerated using the code provided, for convenience CSV files of the data shown in each graph are also provided, along with appropriate metadata written in the Ecological Metadata Language (EML).  

-->



```{r figure_S3, fig.height=6, fig.cap="Traces from the MCMC estimates of the Ricker model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps)", fig.width=6}
plot_ricker_traces
```

```{r figure_S4, fig.cap="Posteriors from the MCMC estimate of the Ricker model", fig.width=6, fig.height=4}
ggplot(ricker_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(ricker_posteriors, "components/data/ricker_posteriors.csv")
```


```{r Table S1, results = "asis"}
pander::pandoc.table(ricker_priors_xtable,
  caption = "Parameterization range for the uniform priors in the Ricker model")
```


```{r figure_S5, fig.height=6, fig.cap="Traces from the MCMC estimates of the Myers model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps)", fig.width=6}
plot_myers_traces
```

```{r figure_S6, fig.cap="Posterior distributions from the MCMC estimates of the Myers model", fig.width=6, fig.height=6}
ggplot(myers_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(myers_posteriors, "components/data/myers_posteriors.csv")
```


```{r TableS2, results="asis"}
pander::pandoc.table(myers_priors_xtable,
           caption = "Parameterization range for the uniform priors in the Myers model")
```


```{r figure_S7, fig.height=6, fig.cap="Traces from the MCMC estimates of the Allen model show reasonable mixing (no trend) and sampling rejection rate (no piecewise jumps)", fig.width=6}
plot_allen_traces
```

```{r figure_S8, fig.cap="Posteriors from the MCMC estimate of the Allen model", fig.width=6, fig.height=6}
ggplot(allen_posteriors, aes(value)) + 
  stat_density(geom="path", position="identity") +
  facet_wrap(~ variable, scale="free", ncol=2)
write.csv(allen_posteriors, "components/data/allen_posteriors.csv")
```


```{r TableS3, results = "asis"}
pander::pandoc.table(allen_priors_xtable,
  caption = "Parameterization range for the uniform priors in the Allen model")
```



Further sensitivity analysis
=============================

The Latin hypercube approach systematically varies all combinations of
parameters, providing a more general test than varying only one parameter
at a time.  We loop across eight replicates of three different randomly
generated parameter sets for each of two different generating models
(Allen and Myers) over two different noise levels (0.01 and 0.05),
for a total of 8 x 3 x 2 x 2 = 96 scenarios. The Gaussian Process performs
nearly optimally in each case, relative to the optimal solution with no
parameter or model uncertainty (Figure S10, appendix).  



```{r sensitivity-calc}
source("components/sensitivity.R")

models <- c("Myers","Allen")

parameters <- list(
  Myers = list(
    c(r=1.5 + rnorm(1, 0, 1), theta=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1)),
    c(r=1.5 + rnorm(1, 0, 1), theta=2.5 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1))),
  Allen = list(
    c(r=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1), C=4 + rnorm(1, 0, 1)),
    c(r=2 + rnorm(1, 0, 1), K=10 + rnorm(1, 0, 1), C=4 + rnorm(1, 0, 1)))
)
nuisance_pars <- c("sigma_g")
nuisance_values <- list(sigma_g = c(0.01, 0.05))
```

```{r allensets}
model <- "Allen"
allen1.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
allen2.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
allen1.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
allen2.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
```

```{r myerssets}
model <- "Myers"
Myers1.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
Myers2.01 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[1]), 
                   seed=c(1111, 2222, 3333))
Myers1.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[1]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))
Myers2.05 <- sensitivity(model, 
                   parameters = parameters[[model]][[2]], 
                   nuisance = c(sigma_g = nuisance_values$sigma_g[2]), 
                   seed=c(1111, 2222, 3333))

## Assemble into data.frame
allen_dat <- rbind(allen1.01, allen1.05, allen2.01, allen2.05) 
m <- rbind(Myers1.01, Myers1.05, Myers2.01, Myers2.05)
myers_dat <- m[c(1:2,4,3,5:8)]
names(myers_dat) <- names(allen_dat)
model_dat <- rbind(allen_dat, myers_dat)
dat <- model_dat
dat$pars.r <- factor(dat$pars.r, labels=c("A", "B", "C", "D"))
dat <- dat[c(1:2,5:6, 8, 7)]
dat$noise <- factor(dat$noise)
names(dat) <- c("model", "parameters", "replicate", "simulation", "noise", "value")

## Extract acutal parameter values corresponding to each parameter set
p1 = as.numeric(levels(factor(model_dat$pars.r)))
p2 = as.numeric(levels(factor(model_dat$pars.K)))
p3 = as.numeric(levels(factor(model_dat$pars.C)))

set.A = c(r = p1[1], K = p2[1], theta = p3[1])
set.B = c(r = p1[2], K = p2[2], theta = p3[2])
set.C = c(r = p1[3], K = p2[3], C = p3[3])
set.D = c(r = p1[4], K = p2[4], C = p3[4])
AllenParameterSets <- rbind(set.A, set.B)
MyersParameterSets <- rbind(set.C, set.D)

sensitivity_dat <- dat
```

```{r figure_S9, fig.height=6, fig.width=10, dependson=c("sensitivity-calc", "export-data"), fig.cap="Sensitivity Analysis.  Histograms shows the ratio of the realized net present value derived when managing under the GPDP over the optimal value given the true model and true parameters. Values of 1 indicate optimal performance. Columns indicate different models, rows different noise levels, and colors indicate the parameter set used. Grouped over stochastic replicates applying the contol policy and stochastic replicates of training data generated from the model indicated, see raw data for details. Randomly chosen parameter values for the models shown in tables below."}
ggplot(sensitivity_dat) + 
  geom_histogram(aes(value, fill=parameters)) + 
  xlim(0,1.0) + 
  theme_bw() + 
  xlab("value as fraction of the optimal") + 
  facet_grid(noise~model)
write.csv(sensitivity_dat, "components/data/sensitivity_dat.csv") 
```

```{r AllenSetsTable, results="asis"}
pandoc.table(AllenParameterSets, caption="Randomly chosen parameter sets for the Allen models in Figure S9." )
```
```{r MyersSetsTable, results="asis"}
pandoc.table(MyersParameterSets, caption="Randomly chosen parameter sets for the Myers models in Figure S9." )
```

```{r unlink, include=FALSE}
unlink("ricker_process.bugs")
unlink("allen_process.bugs")
unlink("myers_process.bugs")
```
