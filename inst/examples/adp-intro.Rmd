## Introductory examples in approximate dynamic programming

```{r  setup, echo=FALSE, cache=FALSE}
require(multipleuncertainty)
require(reshape2)
require(ggplot2)
require(data.table)
````

```{r plotting, include=FALSE}
opts_knit$set(upload.fun = socialR::flickr.url)
opts_chunk$set(dev.args=list(bg="transparent"), 
               cache=TRUE, cache.path = "adp/",
               comment=NA, message=FALSE, warning=FALSE)
```




### Alogorithm 1 

Based on Powell 2006, page 97.  


```{r}
a <- 1.5
b <- .5
f <- function(x, z) z * a * x / (x + b)
```

We begin with a simulation method $X_{t+1} = f(X_t, Z_t)$.  For illustration, let us consider $f(X_t, Z_t) = Z_t \frac{a X_t}{b + X_t}$ with a = `r a` and b = `r b`.  We define a statespace $S$


```{r}
S <- seq(0, 1, length=10) 
```

as a uniform grid of `r length(S)` points from `r min(S)` to `r max(S)`.  We also need a value function on the state space, $C_t(S_t)$. For simplicity, we set the price of harvest at unity and the cost of harvesting at zero, so that $C_t(S_t, x_t) = \min(x_t, S_t)$.  
($C_t$ is sometimes denoted $\mathbb{\Pi}$).  We also need an action space $\chi_t$ of possible harvest values.  Again for simplicity we assume that harvest can be set to any possible state size, $\chi_t \equiv S_t$,

```r
chi <- S
```



```{r}
T <- 10
N <- 10
```

The approximate dynamic programming algorithm will perform a finite number $N$ = `r N$ iterations over a window of time $T$ =`r T` in our example.  The algorithm can be described as follows: 


- **Step 0**
  - Initialize some $\tilde V_t^0(S_t)$ for all states $S_t$ 
  where the superscripts denote iterations in the forward approximation.  As we know absolutely nothing yet to base our initial guess on, we just arbitrarily set this to zero.  

```{r}
V <- numeric(length(S))
```
  
  - Choose some initial state $S_0^1$
  We start at some initial state for $n = 1$ (superscript) and $t = 0$ (subscript). The choice of initial condition may come from the problem itself, otherwise we choose something arbitrarily.  

```{r}
S_0 <- 0.5
```

  - Set $n = 1$

- **Step 1**: Choose a sample path, $\omega^n$

```r
Z <- lnorm(T)
```

- ** Step 2**: For $t = 0, 1, 2, \ldots, T$, do:

  - Solve:

$$V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{s^{\prime} \in mathcal{S}} \mathbb{P}(s^{\prime} | S_t^n, x_t) V_{t+1}^{n-1} s^{\prime} \right)

Let's start with $t=0$, $n=1$ and fix an $x_0$ from the set of $\chi$ (allowing the action space to be the same in each period, we can omit the subscript on $\chi$) to get started.  We first compute $C(S_0, x_0)$. $S_0 = S_0^1$ which we fixed in step 0b arbitrarily at `r S_0`.  Taking $x_0$ as the smallest harvest, $\min(\chi)$ = `r min(chi)` and evaluating $C(S_0,X_0) = \min(S_0, X_0)$ gives us `r min(S_0, min(chi))`, rather trivially.  

The next terms depend on the value $\tilde V^0_1(s^{\prime})$ for all $s^{\prime} \in S$, which we have no idea about.  Fortunately we have assumed a value for each of these in step 0a.  

We must also come up with some values for the probability $\mathbb{P}(s^{\prime} | S_1^0, x_1)$ for each state, given our current state $S_1^0$ and considered action $x_1$.  This is more straight forward, since it is determined by our one-step transition function (without simulation - recall that the single step transition is given exactly).   

To do so, we evaluate the argument for each value in our action space, $x_t \in \chi_t$,

```{r}
s <- S_0

sapply(0:T, function(t){
  max(
    arg <- sapply(chi, function(x){
      min(s, x) + 
    c(x.n_t = which.max(arg), v.n_t = max(arg)) 
    
```

