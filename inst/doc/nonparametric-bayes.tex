\documentclass[author-year, review]{elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}
\usepackage{lineno} % add 
%\linenumbers % turns line numbering on 
\bibliographystyle{elsarticle-harv}
\biboptions{sort&compress} % For natbib
\usepackage{graphicx}
\usepackage{booktabs} % book-quality tables
%% Redefines the elsarticle footer
\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\it \hfill\today}%
 \let\@evenfoot\@oddfoot}
\makeatother

% A modified page layout
\textwidth 6.75in
\oddsidemargin -0.15in
\evensidemargin -0.15in
\textheight 9in
\topmargin -0.5in
%%%%%%%%%%%%%%%% end my additions to header



\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx}
% We will generate all images so they have a width \maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=\maxwidth]{#1}}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Avoiding tipping points in the management of ecological systems: a non-parametric Bayesian approach},
            colorlinks=true,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
% Pandoc toggle for numbering sections (defaults to be off)
\setcounter{secnumdepth}{0}
% Pandoc header



\begin{document}
\begin{frontmatter}

  \title{Avoiding tipping points in the management of ecological systems: a
non-parametric Bayesian approach}
    \author[cstar]{Carl Boettiger\corref{c1}}
   \ead{cboettig@gmail.com} 
   \cortext[c1]{Corresponding author}
    \author[cstar]{Marc Mangel}
  
  
    \author[noaa]{Stephan Munch}
  
  
      \address[cstar]{Center for Stock Assessment Research, Department of Applied Math and
Statistics, University of California, Mail Stop SOE-2, Santa Cruz, CA
95064, USA}    
    \address[noaa]{Southwest Fisheries Science Center, National Oceanic and Atmospheric
Administration, 110 Shaffer Road, Santa Cruz, CA 95060, USA}    
  


%  \author[cstar]{Marc Mangel}
%  \author[noaa]{Stephan B. Munch}
%  \address[cstar]{Center for Stock Assessment Research, Department of Applied Math and Statistics, University of California, Mail Stop SOE-2, Santa Cruz, CA 95064, USA}
%  \address[noaa]{Southwest Fisheries Science Center, National Oceanic and Atmospheric Administration, 110 Shaffer Road, Santa Cruz, CA 95060, USA}

  \begin{abstract}
  Model uncertainty and limited data coverage are fundamental challenges
  to robust ecosystem management. These challenges are acutely highlighted
  by concerns that many ecological systems may contain tipping points.
  Before a collapse, we do not know where the tipping points lie, if the
  exist at all. Hence, we know neither a complete model of the system
  dynamics nor do we have access to data in some large region of
  state-space where such a tipping point might exist. These two sources of
  uncertainty frustrate state-of-the-art parametric approaches to decision
  theory and optimal control. I will illustrate how a non-parametric
  approach using a Gaussian Process prior provides a more flexible
  representation of this inherent uncertainty. Consequently, we can adapt
  the Gaussian Process prior to a stochastic dynamic programming framework
  in order to make robust management predictions under both model and
  uncertainty and limited data.
  \end{abstract}

 \end{frontmatter}


\section{Introduction}\label{introduction}

Decision making under uncertainty is a ubiquitous challenge of natural
resource management and conservation. Ecological dynamics are frequently
complex and difficult to measure, making uncertainty in our
understanding a prediction a persistent challenge to effective
management. Decision-theoretic approaches provide a framework to
determine the best sequence of actions in face of uncertainty, but only
when that uncertainty can be meaningfully quantified ({\textbf{???}}).
The sudden collapse of fisheries and other ecosystems has increasingly
emphasized the difficulties of formulating even qualitatively correct
models of the underlying processes.

We develop these concerns in the context of fisheries, though the
underlying challenges and methods are germane to many other conservation
and resource management problems. The economic value and ecological
concern have made marine fisheries the crucible for much of the founding
work ({\textbf{???}}; {\textbf{???}}; {\textbf{???}}; {\textbf{???}}) in
managing ecosystems under uncertainty. Global trends ({\textbf{???}})
and controversy ({\textbf{???}}; {\textbf{???}}) have made understanding
these challenges all the more pressing.

Uncertainty enters the decision-making process at many levels: intrinsic
stochasticity in biological processes, measurements, and implementation
of policy ({\textbf{???}}; {\textbf{???}}; {\textbf{???}};
{\textbf{???}}), parameteric uncertainty ({\textbf{???}};
{\textbf{???}}; {\textbf{???}}; {\textbf{???}}), and model or structural
uncertainty ({\textbf{???}}; {\textbf{???}}; {\textbf{???}}). Of these,
structural uncertainty incorporates the least a priori knowledge or
assumptions and is generally the hardest to quantify. Typical approaches
assume a weak notion of model uncertainty in which the correct model (or
reasonable approximation) of the dynamics must be identified from among
a handful of alternative models. Here we consider an approach that
addresses uncertainty at each of these levels without assuming the
dynamics follow a particular (i.e.~parametric) structure.

\emph{Cut the next three paragraphs, since they are covered more
consisely in the above paragraph?}

\subsubsection{Process, measurement, and implementation
error}\label{process-measurement-and-implementation-error}

Resource management and conservation planning seek to determine the
optimal set of feasible actions to maximize the value of some objectives
(e.g ({\textbf{???}})). Process error, measurement error, implementation
error ({\textbf{???}}). These sources of stochasticity in turn mean that
model parameters can only be estimated approximately, requiring
parametric uncertainty also be considered ({\textbf{???}}).

\subsubsection{Parametric uncertainty}\label{parametric-uncertainty}

As the parameter values for these models must be estimated from limited
data, there will always be some uncertainty associated with these
values. This uncertainty further compounds the intrinsic variability
introduced by demographic or environmental noise. The degree of
uncertainty in the parameter values can be inferred from the data and
reflected in the estimates of the transition probabilities
({\textbf{???}}; {\textbf{???}}; {\textbf{???}}; {\textbf{???}}).

\subsubsection{Structural (model)
uncertainty}\label{structural-model-uncertainty}

Estimates of parameter uncertainty are only as good as the parametric
models themselves. Often we do not understand the system dynamics well
enough to know if a model provides a good approximation over the
relevant range of states and timescales (criteria that we loosely refer
to as defining the ``right'' or ``true'' model.) So called structural or
model uncertainty is a more difficult problem than parametric
uncertainty. Typical solutions involve either model choice, model
averaging, or introducing yet greater model complexity of which others
may be special cases (model averaging being one such way to construct
such a model) ({\textbf{???}}; {\textbf{???}}; {\textbf{???}}). Even
setting aside other computational and statistical concerns (e.g.
({\textbf{???}})), these approaches do not address our second concern -
representing uncertainty outside the observed data range.

Model uncertainty is particularly insidious when model predictions must
be made outside of the range of data on which the model was estimated.
This extrapolation uncertainty is felt most keenly in decision-theoretic
(or optimal control) applications, since (a) exploring the potential
action space typically involves considering actions that may move the
system outside the range of observed behavior, and (b)
decision-theoretic alogrithms rely not only on reasonable estimates of
the expected outcomes, but depend on the weights given to all possible
outcomes ({\textbf{???}}). If we are observing the fluctuations of a
given fish stock over many years under a fixed harvesting pressure, we
might develop and test a model that could reasonably predict the
frequency of a deviation of a given size, even when such a deviation has
not been previously observed. Yet such predictions are far less reliable
when extrapolated to a harvest pressure that has not yet been observed.
Thus, model uncertainty can be particularly challenging in the
management and decision-making context.

This difficult position of having neither the true model nor data that
covers the full range of possible states is unfortunately the rule more
than the exception. The potential concern of tipping points in
ecological dyanmics ({\textbf{???}}; {\textbf{???}}) reflects these
concerns -- as either knowledge of the true model or more complete
sampling of the state space would make it easy to identify if a tipping
point existed. If we do not know but cannot rule out such a possibility,
then we face decision-making under this dual challege of model
uncertainty and incomplete data coverage.

These dual concerns pose a substantial challenge to existing
decision-theoretic approaches ({\textbf{???}}). Because intervention is
often too late after a tipping point has been crossed (but see
({\textbf{???}})), management is most often concerned with avoiding
potentially catastrophic tipping points before any data is available at
or following a transition that would more clearly reveal these regime
shift dynamics ({\textbf{???}}).

Here we illustrate how a stochastic dynamic programming (SDP) algorithm
({\textbf{???}}; {\textbf{???}}) can be driven by the predictions from a
Bayesian non-parametric (BNP) approach ({\textbf{???}}). This provides
two distinct advantages compared with contemporary approaches. First,
using a BNP sidesteps the need for an accurate model-based description
of the system dynamics. Second, the BNP can better reflect uncertainty
that arises when extrapolating a model outside of the data on which it
was fit. We illustrate that when the correct model is not known, this
latter feature is crucial to providing a robust decision-theoretic
approach in face of substantial structural uncertainty.

This paper represents the first time the SDP decision-making framework
has been used without an a priori model of the underlying dynamics
through the use of the BNP approach. In contrast to parametric models
which can only reflect uncertainty in parameter estimates, the BNP
approach provides a more state-space dependent representation of
uncertainty. This permits a much greater uncertainty far from the
observed data than near the observed data. These features allow the
GP-SDP approach to find robust management solutions in face of limited
data and without knowledge of the correct model structure.

The idea that any approach can perform well without either having to
know the model or have particularly good data should immediately draw
suspicion. The reader must bear in mind that the strength of our
approach comes not from black-box predictive power from such limited
information, but rather, by providing a more honest expression of
uncertainty outside the observed data without sacrificing the predictive
capacity near the observed data. By coupling this more accurate
description of what is known and unknown to the decision-making under
uncertainty framework provided by stochastic dynamic programming, we are
able to obtain more robust management policies than with common
parametric modeling approaches.

The nature of decision-making problems provides a convenient way to
compare models. Rather than compare models in terms of best fit to data
or fret over the appropriate penalty for model complexity, model
performance is defined in the concrete terms of the decision-maker's
objective function, which we will take as given. (Much argument can be
made over the `correct' objective function, e.g.~how to account for the
social value of fish left in the sea vs.~the commercial value of fish
harvested; see ({\textbf{???}}) for further discussion of this issue.
Alternatively, we can always compare model performance across multiple
potential objective functions.) The decision-maker does not necessarily
need a model that provides the best mechanistic understanding or the
best long-term outcome, but rather the one that best estimates the
probabilities of being in different states as a result of the possible
actions.

\subsection{Background on the Gaussian
Process}\label{background-on-the-gaussian-process}

Addressing the difficulty posed by extrapolation without knowing the
true model requires a nonparametric approach to model fitting: one that
does not assume a fixed structure but rather depends on the size of the
data (e.g.~non-parametric regression or a Dirichlet process). This
established terminology is nevertheless unfortunate, as (a) this
approach still involves the estimation of parameters, and (b),
Statisticians use non-parametric to mean both this property (structure
is not fixed by the parameters) and an entirely different (and probably
more familiar) case in which the model does not assume any distribution
(e.g.~non-parametric bootstrap, order statistics). Some literature thus
uses the term semi-parametric, which merely adds ambiguity to the
confusion.

This non-parametric property -- having a structure explicitly dependent
on the data -- is precisely the property that makes this approach
attractive in face of the limited data sampling challenges discussed
above. Having fit a parametric model to some data, the model is
completely described by the values (or posterior distributions) of it's
parameters. The non-parametric model is not captured by its parameter
values or distributions alone. Either the model scales with the
complexity of the data on which it is estimated (e.g.~nonparametric
heirarchical approaches such as the Dirchlet process) or the data points
become themselves part of the model specification, as in the
nonparametric regression used here.

The use of Gaussian process (GP) regression (or ``kriging'' in the
geospatial literature) to formulate a predictive model is relatively new
in the context of modeling dynamical systems ({\textbf{???}}), and was
first introduced in the context ecological modeling and fisheries
management in ({\textbf{???}}). An accessible and thorough introduction
to the formulation and use of GPs can be found in ({\textbf{???}}).

The posterior distribution for the hyper-parameters of the Gaussian
process model are estimated by Metropolis-Hastings algorithm, again with
details and code provided in the Appendix. ({\textbf{???}}) provides an
excellent general introduction to Gaussian Processes and
({\textbf{???}}) first discusses their application in the context of
population dynamics models such as fisheries stock-recruitment
relationships.

\section{Approach and Methods}\label{approach-and-methods}

\subsubsection{Statement of the optimal control
problem}\label{statement-of-the-optimal-control-problem}

To illustrate the application of the BNP-SDP approach and compare to the
predictions of the alternative parametric models we focus on the
classical problem of selecting the appropriate harvest level given an
observation of the stock size in the previous year ({\textbf{???}};
{\textbf{???}}; {\textbf{???}}). Given this observation and the model
(together with the parameter uncertainty) of the stock recruitment
process, the manager seeks to maximize the value of the fishery over a
fixed time interval of 50 years at a discount rate of 0.01. The value
function (profits) at time $t$ depends on the true stock size $x_t$ and
the chosen harvest level $h_t$. For simplicity we assume profit is
simply proportional in the realized harvest (only enforcing the
restriction that harvest can not exceed available stock).

\subsubsection{Parametric models}\label{parametric-models}

We consider three candidate parametric models of the stock-recruitment
dynamics: The Ricker model, the Allen model ({\textbf{???}}), the Myers
model ({\textbf{???}}). The familiar Ricker model involves two
parameters, corresponding to a growth rate and a carrying capacity, and
cannot support alternative stable state dynamics (though as growth rate
increases it exhibits a periodic attractor that proceeds through
period-doubling into chaos. We will generally focus on dynamics below
the chaotic threshold for the purposes of this analysis.) The Allen
model resembles the Ricker dynamics with an added Allee effect parameter
({\textbf{???}}), below which the population cannot persist. The Myers
model also has three parameters and contains an Allee threshold, but has
compensatory rather than over-compensatory density dependence
(resembling a Beverton-Holt curve rather than a Ricker curve at high
densities.)\\We assume multiplicative log-normal noise perturbs the
growth predicted by the each of the deterministic model skeletons
described above. This introduces one additional parameter $\sigma$ that
must be estimated by each model.

As we simulate training data from the Allen model, we will refer to this
as the structurally correct model. The Ricker model is thus a reasonable
approximation of these dynamics far from the Allee threshold (but lacks
threshold dynamics), while the Myers model shares the essential feature
of a threshold but differs in the structure. Thus we have three
potential parametric models of the stock dynamics.

We introduce parameteric uncertainty by first estimating each of the
candidate models from data on unexploited stock dynamics following some
pertubation (non-equilibrium initial condition) over several time steps.
This training data could be generated in several different ways (such as
known variable exploitation rates, etc), as long as it reflects the
dynamics in some limited region of state space without impacting the
problem. We consider a period of 40 years of training data: long enough
that the estimates are not dependent on the particular realization,
while longer times are not likely to provide substantial improvement
(i.e.~the results are not sensitive to this interval). Each of the
models (described below) is fit to the same training data, as shown in
Figure 1.

We infer posterior distributions for the parameters of each model in a
Bayesian context using Gibbs sampling (implemented in R ({\textbf{???}})
using jags, ({\textbf{???}})). We choose uninformative uniform priors
for all parameters (See Appendix, Figures S1-S3, and Table S1, and the R
code provided). One-step-ahead predictions of these model fits are shown
in Figure 1.

An optimal policy function is then inferred through stochastic dynamic
programming for each model given the posterior distributions of the
parameter estimates. This policy maximizes the expectation of the value
function integrated over the parameter uncertainty. (code implementing
this algorithm provided in the Appendix).

\subsubsection{The Gaussian Process
model}\label{the-gaussian-process-model}

We also estimate a simple Gaussian Process defined by a radial basis
function kernel of two parameters: $\ell$, which gives the
characteristic length-scale over which correlation between two points in
state-space decays, and $\sigma$, which gives the scale of the process
noise by which observations $Y_{t+1}$ may differ from their predicted
values $X_{t+1}$ given an observation of the previous state, $X_t$.
({\textbf{???}}) gives an accessible introduction to the use of Gaussian
Processes in providing a Bayesian nonparametric description of the
stock-recruitment relationship.

We use a Metropolis-Hastings Markov Chain Monte Carlo to infer posterior
distributions of the two parameters of the GP (Figure S13, code in
appendix), under weakly informative Gaussian priors (see parameters in
table S5). As the posterior distributions differ substantially from the
priors (Figure S13), we can be assured that most of the information in
the posterior comes from the data rather than the prior belief.

Though we are unaware of prior application of this type, it is
reasonably straight-forward to adapt the Gaussian Process for Stochastic
Dynamic Programming. Recall that unlike the parametric models the
Gaussian process with fixed parameters already predicts a distribution
of curves rather than a single curve. We must first integrate over this
distribution of curves given a sampling of parameter values drawn from
the posterior distribution of the two GP parameters, before integrating
over the posterior of those parameters themselves.

\section{Results}\label{results}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-Figureb_posteriors.pdf}
\caption{Points show the training data of stock-size over time. Curves
show the posterior step-ahead predictions based on each of the estimated
models.}
\end{figure}

All models fit the observed data rather closely and with relatively
small uncertainty, as illustrated in the posterior predictive curves in
Figure 1. Figure 1 shows the training data of stock sizes observed over
time as points, overlaid with the step-ahead predictions of each
estimated model using the parameters sampled from their posterior
distributions. Each model manages to fit the observed data rather
closely. Compared to the expected value of the true model most estimates
appear to overfit, predicting fluctuations that are actually due purely
to stochasticity in growth rate. Model-choice criteria shown in Table 1
penalize more complex models and show a slight preference for the
simpler Ricker model over the more complicated alternate stable state
models (Allen and Myers). Details on MCMC estimates for each model,
traces, and posterior distributions can be found in the appendix.

\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrr}
  \hline
 & Allen & Ricker & Myers \\ 
  \hline
DIC & 50.14 & 49.45 & 50.61 \\ 
  AIC & -24.60 & -30.07 & -27.19 \\ 
  BIC & -17.85 & -25.00 & -20.44 \\ 
   \hline
\end{tabular}
\caption{Model choice scores for several common criteria all (wrongly) select the simplest model. As the true (Allen) model is not distinguishable from the simpler (Ricker) model in the region of the observed data, this error cannot be avoided regardless of the model choice criterion. This highlights the danger of model choice when the selected model will be used outside of the observed range of the data.}
\end{center}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-statespace_posteriors.pdf}
\caption{Graph of the inferred Gaussian process compared to the true
process and maximum-likelihood estimated process. Graph shows the
expected value for the function $f$ under each model. Two standard
deviations from the estimated Gaussian process covariance with (light
grey) and without (darker grey) measurement error are also shown. The
training data is also shown as black points. The GP is conditioned on
(0,0), shown as a pseudo-data point.}
\end{figure}

The mean inferred state space dynamics of each model relative to the
true model used to generate the data is shown in Figure 2, predicting
the relationship between observed stock size (x-axis) to the stock size
after recruitment the following year. Note that in contrast to the other
models shown, the expected Gaussian process corresponds to a
distribution of curves - as indicated by the gray band - which itself
has a mean shown in black. Parameter uncertainty (not shown) spreads out
the estimates further. The observed data from which each model is
estimated is also shown. The observations come from only a limited
region of state space corresponding to unharvested or weakly harvested
system. No observations occur at the theoretical optimum harvest rate or
near the tipping point.

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-out_of_sample_predictions.pdf}
\caption{Out of sample predictions of the dynamics under each model.
Points show the stock size simulated by the true model. Overlay shows
the range of states predicted by each model, based on the state observed
in the previous time step. The Ricker model always predicts population
growth, while the actual population shrinks in each step as the initial
condition falls below the Allee threshold of the underlying model
(Allen). Note that the GP is both more pessimistic and more uncertain
about the future state than the parameteric models, while the realized
state often falls outside of the expected range forecasted by the
structurally incorrect Myers and Ricker models.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-Figure2.pdf}
\caption{The steady-state optimal policy (infinite boundary) calculated
under each model. Policies are shown in terms of target escapement,
$S_t$, as under models such as this a constant escapement policy is
expected to be optimal ({\textbf{???}}).}
\end{figure}

Despite the similarities in model fits to the observed data, the
policies inferred under each model differ widely, as shown in Figure 3.
Policies are shown in terms of target escapement, $S_t$. Under models
such as this a constant escapement policy is expected to be optimal
({\textbf{???}}), whereby population levels below a certain size $S$ are
unharvested, while above that size the harvest strategy aims to return
the population to $S$, resulting in the hockey-stick shaped policies
shown. Only the structurally correct model (Allen model) and the GP
produce policies close to the true optimum policy (where both the
underlying model structure and parameter values are known without
error).

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-Figure3.pdf}
\caption{Gaussian process inference outperforms parametric estimates.
Shown are 100 replicate simulations of the stock dynamics (eq 1) under
the policies derived from each of the estimated models, as well as the
policy based on the exact underlying model.}
\end{figure}

The consequences of managing 100 replicate realizations of the simulated
fishery under each of the policies estimated is shown in Figure 4. As
expected from the policy curves, the structurally correct model
under-harvests, leaving the stock to vary around it's un-fished optimum.
The structurally incorrect Ricker model over-harvests the population
passed the tipping point consistently, resulting in the immediate crash
of the stock and thus derives minimal profits.

These results are robust across a range of stochastic realizations,
models, and parameter values. The results across this range can most
easily be compared by using the relative differences in net present
value realized by each of the model, as shown in Figure 5. The BNP-SDP
approach most consistently realizes a value close to the optimal
solution, and importantly avoids ever driving the system across the
tipping point, which results in the near-zero value cases in the
parametric models.

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-Figure4.pdf}
\caption{Histograms of the realized net present value of the fishery
over a range of simulated data and resulting parameter estimates. For
each data set, the three models are estimated as described above. Values
plotted are the averages of a given policy over 100 replicate
simulations. Details and code provided in the supplement.}
\end{figure}

\section{Discussion}\label{discussion}

In any modeling effort, models must be chosen for the task at hand.
Though simple mechanistically motivated models offer the greatest
potential to increase our basic understanding of ecological processes
({\textbf{???}}; {\textbf{???}}), such models can be not only inaccurate
but misleading when relied upon in a quantitative decision making
framework. In this paper we have tackled two aspects of uncertainty that
are both common to many ecological desicion-making problems and
fundamentally challenging to existing approaches which largely rely on
parametric models:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  We do not know what the correct models are for ecological systems.
\item
  We have limited data from which to estimate the model -- in
  particular, such models may be misleading in predicting the
  probability of outcomes outside the training data.
\end{enumerate}

We have illustrated how the use of non-parametric approaches can provide
more reliable solutions in the sequential decision-making problem.

\subsubsection{Traditional model-choice approaches can be positively
misleading.}\label{traditional-model-choice-approaches-can-be-positively-misleading.}

These results illustrate that model-choice approaches would be
positively misleading -- supporting simpler models that cannot express
tipping point dynamics merely on account of them being similar. As the
data shown comes only from the basin of attraction near the unfished
equilibrium, near which all of the models are approximately linear and
approximately identical.

Model choice approaches trade off model complexity and fit to the data.
When the data come from a limited region of state-space -- as is
necessarily the case whenever there is a potential concern about tipping
point dynamics -- simpler models can fit just as well and will tend to
outperform more complex ones. This approach would be appropriate when
the dynamics can be expected to remain in the region of the training
data; for instance, if we only considered the forecasting accuracy of
the unfished population dynamics under each model.

In contrast, the decision-maker's problem of setting appropriate harvest
levels cannot exclude regions of state-space outside the observed range
when integrating over all possible decisions to find the optimal choice.
Such problems are not constrained to fisheries management but ubiquitous
across ecological decision-making and conservation where the greatest
concerns involve entering previously unobserved regions of state-space
-- whether that is the collapse of a fishery, the spread of an invasive,
or the loss of habitat.

\subsubsection{BNP-SDP expresses larger uncertainty in regions where the
data are
poor}\label{bnp-sdp-expresses-larger-uncertainty-in-regions-where-the-data-are-poor}

The parametric models perform worst when they propose a management
strategy outside the range of the observed data. The non-parametric
Bayesian approach, in contrast, allows a predictive model that expresses
a great deal of uncertainty about the probable dynamics outside the
observed range, while retaining very good predictive accuracy in the
range observed. The management policy dictated by the GP balance this
uncertainty against the immediate value of the harvest, and act to
stabilize the population dynamics in a region of state space in which
the predictions can be reliably reflected by the data.

\subsubsection{BNP-SDP has good predictive accuracy where data are
good}\label{bnp-sdp-has-good-predictive-accuracy-where-data-are-good}

While expressing larger uncertainty outside the observed data, the GP
can also provide a better fit with smaller uncertainty inside the range
of the observed data. This arises from the greater flexibility of the
Gaussian process, which describes a large family of possible curves.
Despite this flexibility, the GP can be described in relatively few
parameters and is thus far less likely to overfit.

\subsubsection{Risk-prone and risk-adverse value
functions}\label{risk-prone-and-risk-adverse-value-functions}

The degree to which the decision-making part of the algorithm (the SDP)
chooses to explore or avoid the resulting region of uncertainty can also
be influenced by the curvature of the value (profit) function $\Pi$.
Both to simplify the intution and avoid biasing this result, we have
chosen a profits that are linear in the catch and thus neither
risk-prone nor risk adverse. Making this function concave, representing
the typical assumption of diminishing returns, would make the SDP more
risk-adverse (as larger-than-expected stock sizes offer dimished returns
relative to the cost of smaller-than-expected stock sizes), and
strengthen the result shown here in which the BNP solution tends to
avoid the region of uncertainty. Sufficiently convex or risk-prone
functions could lead the SDP to attempt higher exploitation rates
despite the uncertainty. Understanding the relative roles of such
functions would be a promising direction for future investigation.

\subsubsection{The role of the prior}\label{the-role-of-the-prior}

Lastly, it should be noted that outside the data, the NBP reverts to the
prior, and consequently the choice of the prior can also play a
significant role in determining the optimal policy inferred by the SDP.
In the examples shown here we have selected a prior that is both
relatively uninformative (due to the broad priors placed on its
parameters $\ell$ and $\sigma$ and simple (mean zero, radial basis
function kernel). In practice, both the choice of mean and the choice of
the covariance function may be chosen to confer particular biological
properties, as well as more biologically informed priors for $\ell$ and
$\sigma$. In principle, this may allow a manager to improve the
performance of the BNP-SDP approach by adding only enough additional
detail as is justified. For instance, it would be possible to use a
linear or a Ricker-shaped mean in the prior without making the much
stronger assumption that the Ricker is the structurally correct model.
However, this influence raises challenges as well. For instance, in
choosing a trivial mean-zero prior, we bias the dynamics to transitions
to 0 in step $X_{t+1}$ from any stock size $X_t$ in the prior year, in
the absence of any other data. Future research must make sure that both
the prior and the value function are chosen appropriately for the
problem at hand.

\subsection{Future directions}\label{future-directions}

In this simulated example, the underlying dynamics are truly governed by
a simple parametric model, allowing the parametric approaches to be more
accurate. Similarly, because the dynamics are one-dimensional dynamics
and lead to stable nodes (rather than other attractors such as
limit-cycles resulting in oscillations), the training data provides
relatively limited information about the dynamics. For these reasons, we
anticipate that in higher-dimensional examples characteristic of
ecosystem management problems that the machine learning approach will
prove even more valuable.

In our treatment here we have ignored the possibility of learning during
the management phase, in which the additional observations of the stock
size could potentially improve parameter estimates. Of particular
interest in the context of the extreme uncertainty considered here is
the notion of ``active adaptive management'' or ``adaptive probing'',
which may actively seek to reduce uncertainty. The concept of adaptive
probing is one area that has explicitly addressed the extrapolation
uncertainty addressed here, though typically without the additional
issue of model uncertainty. As a result, adaptive probing strategies
suggest rather opposite conclusions than what we observe here. Such
adaptive probing or Dual Control (e.g. ({\textbf{???}})) approaches
trade off short term utility by choosing actions that can reduce
uncertainty. Adaptive probing strategies arise when it is valuable to
intentionally force a system far from the observed values even when the
expected value such actions is low, as it provides much faster learning
and consequent reduction of model uncertainty that can allow greater
value to be derived later on. For instance, ({\textbf{???}}) show that
it may be advantageous to fish an unexploited population very heavily at
first to obtain a better estimate of the recruitment rate. This
intuitive strategy when a population is governed by a Ricker or
Beverton-Holt-like dynamic would clearly be disastrous if instead the
dynamics contained an unforeseen tipping point. The best way to learn
where the edge lies may be to walk up to it, but it is also the most
dangerous. Future work should attempt to understand when such active
adaptive learning is valuable, and when it will increase the risk of an
irreversible transition.

\section{Acknowledgments}\label{acknowledgments}

This work was partially supported by the Center for Stock Assessment
Research, a partnership between the University of California Santa Cruz
and the Fisheries Ecology Division, Southwest Fisheries Science Center,
Santa Cruz, CA and by NSF~grant EF-0924195 to MM and NSF grant
DBI-1306697 to CB.

\appendix

\section{Model definitions and
estimation}\label{model-definitions-and-estimation}

\subsection{Ricker Model}\label{ricker-model}

The Ricker model is given by

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \[X_{t+1} = Z_t X_t e^{r \left(1 - \frac{S_t}{K} \right) } \]
\end{enumerate}

where $Z_t$ is log-normal noise of mean unity and log standard deviation
$\sigma$, representing the stochastic growth, $X_t$ the stock size at
time $t$, $S_t$ the escapement (unharvested population that will recruit
in the following year, $S_t = X_t - h_t$). We place uniform priors on
the growth rate $r$, carrying capacity $K$, and log-normal standard
deviation parameter $\sigma$, over ranges given in Table 1. Posteriors
are inferred by Gibbs sampling using Jags ({\textbf{???}}) (see provided
code).

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-2.pdf}
\caption{Posteriors from the MCMC estimate of the Ricker model}
\end{figure}

\begin{table}[ht]
\begin{center}
\begin{tabular}{rlrr}
  \hline
 & parameter & lower.bound & upper.bound \\ 
  \hline
1 & r0 & 0.01 & 20.00 \\ 
  2 & K & 0.01 & 40.00 \\ 
  3 & sigma & 0.00 & 100.00 \\ 
   \hline
\end{tabular}
\caption{parameterization range for the uniform priors in the Ricker model}
\end{center}
\end{table}

\subsection{Myers Model}\label{myers-model}

The Myers model ({\textbf{???}}) is given by

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{1}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \[ X_{t+1} = Z_t \frac{r S_t^{\theta}}{1 - \frac{S_t^\theta}{K}}\]
\end{enumerate}

where $Z_t$ is log-normal noise of mean unity and log standard deviation
$\sigma$, representing the stochastic growth, $X_t$ the stock size at
time $t$, $S_t$ the escapement (unharvested population that will recruit
in the following year, $S_t = X_t - h_t$). We place uniform priors on
the growth rate $r$, carrying capacity $K$, $\theta$ controls the
strength of the nonlinearity, exhibiting an allee effect for
$\theta \geq 2$, and log-normal standard deviation parameter $\sigma$,
over ranges given in Table 1. Posteriors are inferred by Gibbs sampling
using Jags ({\textbf{???}}) (see code provided).

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-4.pdf}
\caption{Traces from the MCMC estimate of the Myers model}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-5.pdf}
\caption{Posterior distributions from the MCMC estimates of the Myers
model}
\end{figure}

\begin{table}[ht]
\begin{center}
\begin{tabular}{rlrr}
  \hline
 & parameter & lower.bound & upper.bound \\ 
  \hline
1 & r0 & 0.00 & 10.00 \\ 
  2 & K & 0.00 & 40.00 \\ 
  3 & theta & 0.00 & 10.00 \\ 
  4 & sigma & 0.00 & 100.00 \\ 
   \hline
\end{tabular}
\caption{parameterization range for the uniform priors in the Myers model}
\end{center}
\end{table}

\subsection{Allen model}\label{allen-model}

The Allen model ({\textbf{???}}) is given by

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{2}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \[f(S_t) = S_t e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)} \]
\end{enumerate}

where $Z_t$ is log-normal noise of mean unity and log standard deviation
$\sigma$, representing the stochastic growth, $X_t$ the stock size at
time $t$, $S_t$ the escapement (unharvested population that will recruit
in the following year, $S_t = X_t - h_t$). We place uniform priors on
the growth rate $r$, carrying capacity $K$, allee threshold $C$, and
log-normal standard deviation parameter $\sigma$, over ranges given in
Table 1. Posteriors are inferred by Gibbs sampling using Jags
({\textbf{???}}) (see code provided).

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-7.pdf}
\caption{Traces from the MCMC estimate of the Allen model}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-8.pdf}
\caption{Posteriors from the MCMC estimate of the Allen model}
\end{figure}

\begin{table}[ht]
\begin{center}
\begin{tabular}{rlrr}
  \hline
 & parameter & lower.bound & upper.bound \\ 
  \hline
1 & r0 & 0.01 & 6.00 \\ 
  2 & K & 0.01 & 20.00 \\ 
  3 & theta & 0.01 & 20.00 \\ 
  4 & sigma & 0.00 & 100.00 \\ 
   \hline
\end{tabular}
\caption{parameterization range for the uniform priors in the Allen model}
\end{center}
\end{table}

Assuming the data are known with some process noise,

\[y = f(x) + \varepsilon\]

$\varepsilon$ IID normal, variance $\sigma_n^2$. Then under the GP,

\[x|y \sim \mathcal{N}(E,C)\]
\[E = K(X_p, X_o) \left(K(X_o,X_o) - \sigma \mathbb{I} \right)  ^{-1} y\]
\[C = K(X_p, X_p) - K(X_p, X_o) K(X_o,X_o)^{-1} K(X_o, X_p)\]

\}

The marginal likelihood is then given by:

\[\log(p(y | X)) = -\tfrac{1}{2} \mathbf{y}^T (K + \sigma_n^2 \mathbf{I})^{-1} y  - \tfrac{1}{2} \log\left| K + \sigma_n^2 \mathbf{I} \right| - \tfrac{n}{2}\log 2 \pi\]

See ({\textbf{???}}) or ({\textbf{???}}) for a more detailed
introduction.

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-10.pdf}
\caption{Traces from the MCMC estimates of the GP model}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{figure/nonparametric-bayes-unnamed-chunk-11.pdf}
\caption{Posterior distributions from the MCMC estimate of the GP model.
Prior curves shown in red.}
\end{figure}

The Gaussian process priors on both the lengthscale $\ell$ and process
noise $\sigma$ are are inverse Gamma distributed,

\[f(x; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{-\alpha - 1}\exp\left(-\frac{\beta}{x}\right)\]

For the $\sigma$ prior, $\alpha = $ 5 and $\beta = $ 5. For $\ell$
prior, $\alpha = $ 10 and $\beta = $ 10.

\subsection{Optimal Control Problem
Specification}\label{optimal-control-problem-specification}

We seek the harvest policy $h(x)$ that maximizes:

\[ \max_{h_t} \sum_{t \in 0}^{\infty}  \Pi_t(X_t, h_t) \delta^t  \]

subject to the profit function $\Pi(X_t,h)$, discount rate $\delta$, and
the state equation

\[X_{t+1} = Z_t f(S_t)  \] \[S_t = X_t - h_t \]

Where $Z_t$ is multiplicative noise function with mean 1, representing
stochastic growth. We will consider log-normal noise with shape
parameter $\sigma_g$.

Form this we can write down the Bellman recursion as:

\[V_t(x_t) = \max_h \mathbf{E} \left(\Pi(h_t, x_t) + \delta V_{t+1}( Z_{t+1} f(x_t - h_t)) \right)\]

For simplicity we assume profit is simply linear in the realized harvest
(only enforcing the restriction that harvest can not exceed available
stock), $\Pi(h,x) = min(h,x)$.

\subsubsection{Pseudocode for the Bellman
iteration}\label{pseudocode-for-the-bellman-iteration}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# compute the value for each possible harvest}
\NormalTok{for(h in }\DecValTok{1}\NormalTok{:}\KeywordTok{length}\NormalTok{(h_grid))\{}
  \NormalTok{V1[h] =}\StringTok{ }\NormalTok{delta *}\StringTok{ }\NormalTok{F[[h]] %*%}\StringTok{ }\NormalTok{V +}\StringTok{  }\KeywordTok{profit}\NormalTok{(x_grid, h_grid[h]) }
\NormalTok{\}}
\CommentTok{# find havest h that gives the maximum value}
\NormalTok{for(j in }\DecValTok{1}\NormalTok{:gridsize)\{}
  \NormalTok{value =}\StringTok{ }\KeywordTok{max}\NormalTok{(V1[j,], }\DataTypeTok{na.rm =} \NormalTok{T)  }\CommentTok{# each col is a different h, max over these}
  \NormalTok{index =}\StringTok{ }\KeywordTok{which.max}\NormalTok{(V1[j,])       }\CommentTok{# store index so we can recover h's }
  \NormalTok{output[,j] =}\StringTok{ }\KeywordTok{c}\NormalTok{(value, index)    }\CommentTok{# returns both profit value & index of optimal h.  }
\NormalTok{\}}
\CommentTok{# Sets V[t+1] = max_h(V[t]) at each possible state value, x}
\NormalTok{V =}\StringTok{ }\NormalTok{out[}\DecValTok{1}\NormalTok{,]                        }\CommentTok{# The new value-to-go}
\NormalTok{D[,OptTime-time}\DecValTok{+1}\NormalTok{] =}\StringTok{ }\NormalTok{out[}\DecValTok{2}\NormalTok{,]       }\CommentTok{# The index positions}
\end{Highlighting}
\end{Shaded}

\subsection{Training data}\label{training-data}

Eacho of our models $f(S_t)$ must be estimated from training data, which
we simulate from the Allen model with parameters $r = $ 2, $K =$ 8,
$C =$ 5, and $\sigma_g =$ 0.05 for $T=$ 40 timesteps, starting at
initial condition $X_0 = $ 5.5. The training data can be seen in Figure
1.

\subsection{Code}\label{code}

A copy of the script to reconstruct the simulations and analysis shown
here is provided in the supplemental materials, and through this
version-stable link to the project's Github code repostitory,
\href{}{nonparameteric-bayes.R}. This code is dynamically embedded into
the manuscript using Knitr, ({\textbf{???}}). The script relies on
custom routines for executing the estimation of the Gaussian process and
the for solving the stochastic dynamic programming problem. These
routines are provided as an R package, \href{}{nonparameteric-bayes},
also available on Github.

\subsection{Sensitivity Analysis}\label{sensitivity-analysis}

These results are not sensitive to the modeling details of the
simulation. The Gaussian process estimate remains very close to the
optimal solution obtained by knowning the true model across changes to
the training simulation, noise scale, parameters or structure of the
underlying model, as seen in the figure. Results are pooled across
different random seeds (111, 222, 333), noise values of 0.01, 0.05, 0.1,
and 0.2, 3 different randomly generated parameters sets for each model,
and using either the Myers or Allen as the underlying structure.

\begin{figure}[htbp]
\centering
\includegraphics{figure/sensitivity.pdf}
\caption{Sensitivity Analysis}
\end{figure}

\end{document}


