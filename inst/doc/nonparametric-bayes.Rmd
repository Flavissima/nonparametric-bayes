Non-parametric approaches to optimal policy are more robust
===========================================================


```{r knit-settings, cache=FALSE}
      options(xtable.print.comment=FALSE)
      options(xtable.type = 'latex', table.placement="H")
      opts_chunk$set(warning=FALSE, message=FALSE, comment=NA, tidy=FALSE,
                     echo=FALSE)
      opts_knit$set(progress = TRUE, verbose = TRUE)
      opts_chunk$set(dev = 'Cairo_pdf', fig.width=5.5, fig.height=4,
                     cache.path = 'cache-pdf/', cache=TRUE)
```

Carl Boettiger, Steve Munch, Marc Mangel

# Abstract


# Introduction

The problem of structural uncertainty in managing ecological systems.  

* Most management recommendations from the ecological literature / management policies based on (motivated by) parametric models.  _Preference to pitch towards policy or theoretical literature?_

* Background discussion on the importance/success of parametric modeling; (e.g. @Levins1966, etc., up through @Geritz2011a) 

* Background on the concerns of structural uncertainty -- we don't have the right models.  (Also: measurement uncertainty, parameter uncertainty, unobserved states, boundary conditions, etc.)

* Hierarchical Bayesian approach has provided a natural way to address these from a statistical standpoint.  Successes and challenges from the parametric route: e.g. @Cressie2009.  

* Among pitfalls of these approaches: particularly difficult to apply in management context. Optimization-based (Decision-theoretic) approaches to ecological management need to be precisely parameterized about everything, even the uncertainty itself [@Polasky2011] (discussion of @Brozovic2011 SDP example in context of threshold system would perhaps be useful as well). 

* Management goals / decision-theoretic approaches need accurate prediction over relevant (short?) timescales more than accurate (but incomplete or noisy estimated) mechanisms.  


* Nonparametric (machine-learning?) approaches may offer the benefit of the hierarchical Bayesian approach without the practical and computational limitations of their parametric kin.  Non-parametric models are flexible enough to take maximum advantage of the data available, while being appropriately ambiguous about the dynamics of a system in regions of parameter space that have been poorly or never sampled.  

* Nonparametric approaches are beginning to appear more frequently in ecological and conservation literature (Species distribution models/maxent), including the Gaussian process based approach used here [@Munch2005].  However, such approaches have yet to be applied to the decision-theoretic framework that could guide management decisions, where we expect them to excel for several reasons (1) the ability to make accurate forecasts by more closely approximating the underlying process where data is available (2) remaining appropriately ambiguous where data is not available (3) remaining computationally simple enough to avoid some pitfalls common to hierarchical parametric approaches.  




# Approach and Methods


```{r libraries, include=FALSE}
library(pdgControl)
library(nonparametricbayes)
library(reshape2)
library(ggplot2)
library(data.table)
library(tgp)
library(MCMCpack)
library(plyr)
library(knitcitations)
```
```{r plotting-options, echo=FALSE, include=FALSE}
theme_set(theme_bw(base_size=10))
theme_update(panel.background = element_rect(fill = "transparent",colour = NA),
             plot.background = element_rect(fill = "transparent",colour = NA))
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
#sha <- gsub("^commit ", "", system("git log -n 1", intern=TRUE)[1])
#short_sha <- gsub("(^.{10}).*", "\\1", sha)
#date <- format(Sys.time(), "%Y-%m-%d__%H-%M-%S")
#opts_chunk$set(fig.path = paste("figure/", date, "-", short_sha, "-", sep=""))
```

### Discussion of state equation

```{r stateeq}
f <- RickerAllee
# c(5, 10, 5) is 2-cycle, c(5.5, 10, 5) is 6 cycle, 5.3 is about 4
p <- c(2, 10, 5) 
K <- 10
allee <- 5
```

Concerns over the potential for tipping points in ecological dynamics [@Scheffer2001] highlight the dangers of uncertainty in ecological management and pose a substantial challenge to existing decision-theoretic approaches [@Brozovic2011].  To compare the performance of nonparametric and parametric approaches in an example that is easy to conceptualize, we will focus on a simple parametric model for a single species [derived from fist principles by @Allen2005a] as our underlying "reality".  

\begin{align}
X_{t+1} &= Z_t f(S_t) \\
S_t &= X_t - h_t \\
f(S_t) &= e^{r \left(1 - \frac{S_t}{K}\right)\left(S_t - C\right)}
\end{align}

As a low-dimensional system completely described by three parameters, this scenario should if anything be favorable to a parametric-based approach.  This model contains an Allee effect, or tipping point, below which the population is not self-sustaining and shrinks to zero [@Courchamp2008].


```{r sdp-pars, dependson="stateeq"}
sigma_g <- 0.05
sigma_m <- 0.0
z_g <- function() rlnorm(1, 0, sigma_g)
z_m <- function() 1+(2*runif(1, 0,  1)-1) * sigma_m
x_grid <- seq(0, 1.5 * K, length=101)
h_grid <- x_grid
profit <- function(x,h) pmin(x, h)
delta <- 0.01
OptTime <- 20  # stationarity with unstable models is tricky thing
reward <- 0
xT <- 0
seed_i <- 1
Xo <- K # observations start from
x0 <- Xo # simulation under policy starts from
Tobs <- 35
```

### Brief discussion on choice of model parameters, nuisance parameters

Where $Z_t$ is multiplicative noise function with mean 1, representing stochastic growth. We will consider log-normal noise with shape parameter $\sigma_g$.  We start with an example in which the parameters are $r =$ `r p[1]`, $K =$ `r p[2]`, $C =$ `r p[3]`, and  $\sigma_g =$ `r sigma_g`.


### Discussion of training data

Both parametric and nonparametric approaches will require some training data on which to base their model of the process.  We generate the training data under the model described in Eq 1 for `r Tobs` time steps, under a known but not necessarily optimal sequence of harvest intensities, $h_t$.  For simplicity we imagine a fishery that started from zero harvest pressure and has been gradually increasing the harvest.  (Motivation, alternatives, stationarity, examples without a stable node (limit-cycle models), examples based on observations near a stable node alone, and why that isn't impossible).  


```{r obs, dependson="sdp-pars"}
  obs <- sim_obs(Xo, z_g, f, p, Tobs=Tobs, nz=15, 
                 harvest = sort(rep(seq(0, .5, length=7), 5)), seed = seed_i)
```



### Discussion of maximum likelihood estimated models

```{r mle, dependson="obs"}
alt <- par_est(obs,  init = c(r = p[1], 
                              K = mean(obs$x[obs$x>0]), 
                              s = sigma_g))
est <- par_est_allee(obs, f, p,  
                     init = c(r = p[1] + 1, 
                              K = p[2] + 2, 
                              C = p[3] + 2, 
                              s = sigma_g))
```

We estimate two parametric models from the data using a maximum likelihood approach.  The first model is structurally identical to the true model (Eq 1), differing only in that it's parameters are estimated from the observed data rather than given.  The alternative model is the Ricker model, which is structurally similar and commonly assumed 


(MLE models will assume the noise is log-normal, which it is in the simulation).  


Which estimates a Ricker model with $r =$ `r alt$p[1]`, $K =$ `r alt$p[2]`, and the Allen Allele model with $r =$ `r est$p[1]`, $K =$ `r est$p[2]` and $C =$ `r est$p[3]`.  


### (Brief) Discussion of GP inference

* The use of Gaussian processes for inference in dynamical systems [introduced by @Kocijan2005]

* Gaussian processes in ecological literature [@Munch2005] 


* Our methodology (e.g. following @Munch2005).  

```{r gp-priors}
#inv gamma has mean b / (a - 1) (assuming a>1) and variance b ^ 2 / ((a - 2) * (a - 1) ^ 2) (assuming a>2)
s2.p <- c(5,5)  
tau2.p <- c(5,1)
d.p = c(10, 1/0.1, 10, 1/0.1)
nug.p = c(10, 1/0.1, 10, 1/0.1) # gamma mean
s2_prior <- function(x) dinvgamma(x, s2.p[1], s2.p[2])
tau2_prior <- function(x) dinvgamma(x, tau2.p[1], tau2.p[2])
d_prior <- function(x) dgamma(x, d.p[1], scale = d.p[2]) + dgamma(x, d.p[3], scale = d.p[4])
nug_prior <- function(x) dgamma(x, nug.p[1], scale = nug.p[2]) + dgamma(x, nug.p[3], scale = nug.p[4])
beta0_prior <- function(x, tau) dnorm(x, 0, tau)
beta = c(0)
priors <- list(s2 = s2_prior, tau2 = tau2_prior, beta0 = dnorm, nug = nug_prior, d = d_prior, ldetK = function(x) 0)
```

```{r gp, dependson=c("obs", "gp-priors")}
  gp <- bgp(X=obs$x, XX=x_grid, Z=obs$y, verb=0,
          meanfn="constant", bprior="b0", BTE=c(2000,16000,2),
          m0r1=FALSE, corr="exp", trace=TRUE, 
          beta = beta, s2.p = s2.p, d.p = d.p, nug.p = nug.p, tau2.p = tau2.p,
          s2.lam = "fixed", d.lam = "fixed", nug.lam = "fixed", tau2.lam = "fixed")      
```


###  Discussion of the dynamic programming solution

(More thorough, but general-audience targeted.  Technical details and code provided in appendices).

Outside the ecological community, Gaussian processes have been introduced into optimization literature, but as an approximation to the value function rather than to underlying dynamics [@Deisenroth2009].  


```{r opt, dependson=c("gp", "mle")}
  OPT <- optimal_policy(gp, f, est$f, alt$f,
                        p, est$p, alt$p,
                        x_grid, h_grid, sigma_g, 
                        sigma_g, sigma_g, # est$sigma_g, alt$sigma_g, but those ests are poor
                        delta, xT, profit, reward, OptTime)
```


### Discussion on how we compare performance of policies

```{r sim, dependson="opt"}
dt <- simulate_opt(OPT, f, p, x_grid, h_grid, x0, z_g, profit)
```

* Replicate stochastic simulations 
* Sensitivity analysis (Figure 4).  

# Results

## Figure 1: 

_Shows the inferred Gaussian Process compared to the true and parametric models.  Refer to the appendix for details on the GP posteriors, etc._

```{r gp_plot, dependson=c("gp", "mle", "plotting-options"), fig.cap="Graph of the inferred Gaussian process compared to the true process and maximum-likelihood estimated process.  Graph shows the expected value for the function $f$ under each model.  Two standard deviations from the estimated Gaussian process covariance with (light grey) and without (darker grey) measurement error are also shown.  The training data is also shown as black points.  (The GP is conditioned on 0,0, shown as a pseudo-data point). "}
tgp_dat <- 
    data.frame(  x = gp$XX[[1]], 
                 y = gp$ZZ.km, 
                 ymin = gp$ZZ.km - 2 * sqrt(gp$ZZ.ks2), 
                 ymax = gp$ZZ.km + 2 * sqrt(gp$ZZ.ks2),
                 ymin2 = gp$ZZ.mean - 2 * sqrt(gp$ZZ.vark), 
                 ymax2 = gp$ZZ.mean + 2 * sqrt(gp$ZZ.vark))
  true <- sapply(x_grid, f, 0, p)
  alt_mean <- sapply(x_grid, alt$f, 0, alt$p)
  est_mean <- sapply(x_grid, est$f, 0, est$p)
  models <- data.frame(x=x_grid, GP=tgp_dat$y, 
                       Parametric=est_mean, 
                       True=true, 
                       Structural=alt_mean)
  models <- melt(models, id="x")
  names(models) <- c("x", "method", "value")

ggplot(tgp_dat) + 
  geom_ribbon(aes(x,y,ymin=ymin,ymax=ymax), fill="gray80") +
  geom_ribbon(aes(x,y,ymin=ymin2,ymax=ymax2), fill="gray60") +
  geom_line(data=models, aes(x, value, col=method), alpha=0.8, lwd=1) + 
  geom_point(data=obs, aes(x,y)) + 
  xlab(expression(X[t])) + ylab(expression(X[t+1])) +
  scale_colour_manual(values=cbPalette) 
```


## Figure 2: 

_The take-home message, showing that the GP is closest to the optimal strategy, while the parametric methods are less accurate.  Visualizing the policy may be more useful for the technical reader, the general audience may prefer Figure 3 showing all replicates of the population collapse under the parametric model and not under the GP._

```{r policies_plot, dependson=c("opt", "plotting-options"), fig.cap="The steady-state optimal policy (infinite boundary) calculated under each model.  Policies are shown in terms of target escapement, $S_t$, as under models such as this a constant escapement policy is expected to be optimal [@Reed1979]."}
policies <- 
  melt(data.frame(stock=x_grid, 
                  GP = x_grid[OPT$gp_D], 
                  Parametric = x_grid[OPT$est_D],
                  True = x_grid[OPT$true_D],
                  Structural = x_grid[OPT$alt_D]),
       id="stock")
names(policies) <- c("stock", "method", "value")

ggplot(policies, aes(stock, stock - value, color=method)) +
    geom_line(alpha=0.7, lwd=1) + 
    xlab("stock size") + ylab("escapement")  +
    scale_colour_manual(values=cbPalette)
```

## Figure 3: 

_Figure 3 is a less abstract and more visceral visualization of the take-home message, with the structurally inaccurate model leading universally to a collapse of the fishery and very few profits, while the Gaussian process performs nearly optimally.  The parametric approach even with the correct underlying structure does not perform optimally, choosing in this case to under-fish (may need to show harvest dynamics since that is not clear from the figure! Also isn't general, sometimes does optimally, sometimes over-fishes.  Perhaps need to show more examples.)  May need to show profits too?_ 

```{r sim_plot, dependson=c("sim", "plotting-options"), fig.cap="Gaussian process inference outperforms parametric estimates. Shown are 100 replicate simulations of the stock dynamics (eq 1) under the policies derived from each of the estimated models, as well as the policy based on the exact underlying model."}
ggplot(dt) + 
    geom_line(aes(time, fishstock, 
                  group=interaction(reps, method), 
                  color=method), alpha=.1) +
    scale_colour_manual(values=cbPalette, 
                        guide = guide_legend(override.aes = list(alpha = 1)))
```

## Figure 4:

_Shows the sensitivity analysis.  A histogram of distribution of yield over stochastic realizations, showing that the qualitative results do not depend on the stochastic realization of the training data here, or on the parameters of the underlying model, though quantitative differences are visible._



# Discussion / Conclusion


* Non-parametric methods have received far too little attention in ecological modeling efforts that are aimed at improved conservation planning and decision making support.  

* Importance of non-parametric approaches in conservation planning / resource management / decision theory.  

* Decision-theoretic tools such as optimal control calculations rely on robust _forecasting_ more strongly than they rely on accurate _mechanistic_ relationships.  

* Adapting a non-parametric approach requires modification of existing methods for decision theory.  We have illustrated how this might be done in the context of stochastic dynamic programming, opening the door for substantial further research into how these applications might be improved.  

* Anticipate improved relative performance in higher dimensional examples

* Discuss constant escapement in model, in policies.  

* Limitations of this comparison: Are the maximum-likelihood solutions a straw man?

* Discussion of alternative related approaches: POMDP/MOMDP,  

## Future directions 

* Multiple species
* Online learning
* Multiple step-ahead predictions
* Explicitly accomidating additional uncertainties
* Improving inference of optimal policy from the GP

```{r echo=FALSE, results="asis"}
#bibliography("html")
```


# Appendix / Supplementary Materials

## MCMC posterior distributions and convergence analysis

```{r posteriors, dependson=c("gp", "plotting-options"), fig.cap = "Histogram of posterior distributions for the estimated Gaussian Process shown in Figure 1.  Prior distributions overlaid."}
hyperparameters <- c("index", "s2", "tau2", "beta0", "nug", "d", "ldetK")
posteriors <- melt(gp$trace$XX[[1]][,hyperparameters], id="index")
  prior_curves <- ddply(posteriors, "variable", function(dd){
  grid <- seq(min(dd$value), max(dd$value), length = 100)
  data.frame(value = grid, density = priors[[dd$variable[1]]](grid))
})

ggplot(posteriors) + 
    geom_histogram(aes(x=value, y=..density..), alpha=0.7) +
    geom_line(data=prior_curves, aes(x=value, y=density), col="red") +
    facet_wrap(~ variable, scale="free")
```
 
 @Gramacy2005
 
## Tables of nuisance parameters, sensitivity analysis

### List of hyper-parameters, prior distributions and their parameters

## Reproducible code, "Research Compendium"



