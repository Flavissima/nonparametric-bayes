Non-parametric approaches to optimal policy are more robust
===========================================================

Carl Boettiger, Steve Munch, Marc Mangel


# Introduction

Problem of structural uncertainty in managing ecological systems.  Motivate via the widespread concern of tipping points, more general concerns of complex/nonlinear dynamics.  


Typical approaches using parametric models.  motivation/strengths (mechanistic underpinnings, computationally simple/potentially analytic solutions.  Parametric structure makes it difficult to represent uncertainty accurately in areas where data is not available.  


# Methods


```{r image-options, echo = FALSE, cache = FALSE, external = TRUE, include = FALSE}
opts_chunk$set(cache = TRUE, cache.path = "writeup/", warning = FALSE, message = FALSE,
               comment = NA, tidy = FALSE, echo = FALSE)
opts_knit$set(upload.fun = socialR::notebook.url)
#opts_chunk$set(dev = 'Cairo_pdf', dev.args=list(""))
opts_chunk$set(dev="png", dev.args=list(bg="transparent"))
```
```{r libraries, include=FALSE}
library(pdgControl)
library(nonparametricbayes)
library(reshape2)
library(ggplot2)
library(data.table)
library(tgp)
library(MCMCpack)
library(plyr)
library(knitcitations)
```
```{r plotting-options, echo=FALSE, include=FALSE}
theme_set(theme_bw(base_size=16))
theme_update(panel.background = element_rect(fill = "transparent",colour = NA),
             plot.background = element_rect(fill = "transparent",colour = NA))
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
#sha <- gsub("^commit ", "", system("git log -n 1", intern=TRUE)[1])
#short_sha <- gsub("(^.{10}).*", "\\1", sha)
#date <- format(Sys.time(), "%Y-%m-%d__%H-%M-%S")
#opts_chunk$set(fig.path = paste("figure/", date, "-", short_sha, "-", sep=""))
```

### Discussion of state equation
```{r stateeq}
f <- RickerAllee
# c(5, 10, 5) is 2-cycle, c(5.5, 10, 5) is 6 cycle, 5.3 is about 4
p <- c(2, 10, 5) 
K <- 10
allee <- 5
```


```{r sdp-pars, dependson="stateeq"}
sigma_g <- 0.05
sigma_m <- 0.0
z_g <- function() rlnorm(1, 0, sigma_g)
z_m <- function() 1+(2*runif(1, 0,  1)-1) * sigma_m
x_grid <- seq(0, 1.5 * K, length=101)
h_grid <- x_grid
profit <- function(x,h) pmin(x, h)
delta <- 0.01
OptTime <- 20  # stationarity with unstable models is tricky thing
reward <- 0
xT <- 0
seed_i <- 1
Xo <- K # observations start from
x0 <- Xo # simulation under policy starts from
```

with parameters $r =$ `r p[1]`, $K =$ `r p[2]` and $C =$ `r p[3]`.   




### Discussion of training data
```{r obs, dependson="sdp-pars"}
  obs <- sim_obs(Xo, z_g, f, p, Tobs=35, nz=15, 
                 harvest = sort(rep(seq(0, .5, length=7), 5)), seed = seed_i)
```



### Discussion of maximum likelihood estimated models
```{r mle, dependson="obs"}
alt <- par_est(obs,  init = c(r = p[1], 
                              K = mean(obs$x[obs$x>0]), 
                              s = sigma_g))
est <- par_est_allee(obs, f, p,  
                     init = c(r = p[1] + rnorm(1), 
                              K = p[2] + rnorm(1), 
                              C = p[3] + rnorm(1), 
                              s = sigma_g))
```


Which estimates a Ricker model with $r =$ `r alt$p[1]`, $K =$ `r alt$p[2]`, and the Allen Allele model with $r =$ `r est$p[1]`, $K =$ `r est$p[2]` and $C =$ `r est$p[3]`.  


### (Brief) Discussion of GP inference

The inference of the Gaussian process Following @Munch2005 

```{r gp-priors}
#inv gamma has mean b / (a - 1) (assuming a>1) and variance b ^ 2 / ((a - 2) * (a - 1) ^ 2) (assuming a>2)
s2.p <- c(5,5)  
tau2.p <- c(5,1)
d.p = c(10, 1/0.1, 10, 1/0.1)
nug.p = c(10, 1/0.1, 10, 1/0.1) # gamma mean
s2_prior <- function(x) dinvgamma(x, s2.p[1], s2.p[2])
tau2_prior <- function(x) dinvgamma(x, tau2.p[1], tau2.p[2])
d_prior <- function(x) dgamma(x, d.p[1], scale = d.p[2]) + dgamma(x, d.p[3], scale = d.p[4])
nug_prior <- function(x) dgamma(x, nug.p[1], scale = nug.p[2]) + dgamma(x, nug.p[3], scale = nug.p[4])
beta0_prior <- function(x, tau) dnorm(x, 0, tau)
beta = c(0)
priors <- list(s2 = s2_prior, tau2 = tau2_prior, beta0 = dnorm, nug = nug_prior, d = d_prior, ldetK = function(x) 0)
```

```{r gp, dependson=c("obs", "gp-priors")}
  gp <- bgp(X=obs$x, XX=x_grid, Z=obs$y, verb=0,
          meanfn="constant", bprior="b0", BTE=c(2000,16000,2),
          m0r1=FALSE, corr="exp", trace=TRUE, 
          beta = beta, s2.p = s2.p, d.p = d.p, nug.p = nug.p, tau2.p = tau2.p,
          s2.lam = "fixed", d.lam = "fixed", nug.lam = "fixed", tau2.lam = "fixed")      
```


### (More thorough) Discussion of the dynamic programming solution

```{r opt, dependson=c("gp", "mle")}
  OPT <- optimal_policy(gp, f, est$f, alt$f,
                        p, est$p, alt$p,
                        x_grid, h_grid, sigma_g, 
                        sigma_g, sigma_g, # est$sigma_g, alt$sigma_g, but those ests are poor
                        delta, xT, profit, reward, OptTime)
```


### Discussion on how we compare performance of policies

```{r sim, dependson="opt"}
dt <- simulate_opt(OPT, f, p, x_grid, h_grid, x0, z_g, profit)
```

* Replicate stochastic simulations 
* Sensitivity analysis

# Results

## Figure 1: 

Inferred Gaussian Process compared to the true and parametric models.  

```{r gp_plot, dependson=c("gp", "mle")}
gp_plot(gp, f, p, est$f, est$p, alt$f, alt$p, x_grid, obs, seed_i)
```


## Figure 2: 

```{r policies_plot, dependson="opt"}
  plot_policies(x_grid, OPT$gp_D, OPT$est_D, OPT$true_D, OPT$alt_D)
```

## Figure 3: 

```{r sim_plot, dependson="sim", fig.cap="**Figure 3**: Gaussian process inference outperforms parametric estimates. Shown are 100 replicate simulations of the stock dynamics (eq 1) under the policies derived from each of the estimated models, as well as the policy based on the exact underlying model."}
ggplot(dt) + 
    geom_line(aes(time, fishstock, 
                  group=interaction(reps, method), 
                  color=method), alpha=.1) +
    scale_colour_manual(values=cbPalette, 
                        guide = guide_legend(override.aes = list(alpha = 1)))
```


# Discussion / Conclusion


* Non-parametric methods have received far too little attention in ecological modeling efforts that are aimed at improved conservation planning and decision making support.  

* Importance of non-parametric approaches in conservation planning / resource management / decision theory.  

* Decision-theoretic tools such as optimal control calculations rely on robust _forecasting_ more strongly than they rely on accurate _mechanistic_ relationships.  

* Adapting a non-parametric approach requires modification of existing methods for decision theory.  We have illustrated how this might be done in the context of stochastic dynamic programming, opening the door for substantial further research into how these applications might be improved.  



```{r echo=FALSE, results="asis"}
#bibliography("html")
```


# Appendix / Supplementary Materials

## MCMC posterior distributions and convergence analysis

```{r posteriors, dependson="gp"}
  posteriors_plot(gp, priors) # needs trace=TRUE!
```
 
## Tables of nuisance parameters, sensitivity analysis

## Code, "Research Compendium"



